
```html
注明：
原理部分的内容均来自周志华的西瓜书，真正的大师之作。
其他内容来自开源包文档、开源电子书、ipynb文档等。
```

## 贝叶斯网

贝叶斯网(Bayesian network)亦称“信念网(belief network)”，它借助有向无环图(Directed Acyclic Graph, DAG)来刻画属性之间的依赖关系，并使用条件概率表(Conditional Probability Table, CPT)来描述属性的联合概率分布。

一个贝叶斯网 $B$ 由结构 $G$ 和参数 $\Theta$ 两部分构成，即 $B= \langle G, \Theta \rangle$. 网络结构 $G$ 是一个有向无环图，其每个节点对应一个属性，若两个属性有直接关系，则它们由一条边连接起来；参数 $\Theta$ 定量描述这种依赖关系，假设属性 $x_i$ 在 $G$ 中的父节点集为 $\pi_i$ ，则 $\Theta$ 包含了每个属性的条件概率表 $\theta_{x_i | \pi_i} = P_B (x_i | \pi_i)$.

例子：

西瓜问题的一种贝叶斯网结构和属性‘根蒂’的条件概率表。DAG图中，‘色泽’直接依赖于‘好瓜’和‘甜度’，而‘根蒂’则直接依赖于‘甜度’；从条件概率表能得到‘根蒂’对‘甜度’量化依赖关系，如 $P(\text{根蒂 = 硬挺 | 甜度 = 高}) = 0.1$ 等。

![CPT](./images/xgs_bayesian_network_CPT.png)

### 结构

贝叶斯网结构有效地表达了属性间的条件独立性。给定父节点集，贝叶斯网假设每个属性与它的非后裔属性独立，于是 $B = \langle G, \Theta \rangle$ 将属性 $x_1, x_2, \ldots, x_d$ 的联合概率分布定义为
$$
\tag{7.26} \label{eq:bn_union_proba}
P_B (x_1, x_2, \ldots, x_d) = \prod^d_{i=1} P_B(x_i | \pi_i) = \prod^d_{i=1} \theta_{x_i | \pi_i}.
$$
以**图7.2**为例，联合概率分布定义为
$$
P(x_1, x_2, \ldots, x_5) = P(x_1)P(x_2)P(x_3|x_1)P(x_4|x_1,x_2)P(x_5|x_2),
$$
那么，$x_3$ 和 $x_4$ 在给定 $x_1$ 的取值时独立，记为 $x_3 \perp x_4 | x_1$，类似的，$x_5 \perp x_4 | x_2$.

![dependance](./images/xgs_bayesian_network_dependances.png)

在“同父(common parent)”结构中，给定父节点 $x_1$ 的取值，则 $x_3$ 和 $x_4$ 条件独立。在“顺序”结构中，给定 $x$ 值，则 $y$ 与 $z$ 条件独立。V型结构(V-structure)，也叫做‘冲撞’结构，给定子节点 $x_4$ 的取值，$x_1$ 与 $x_2$ **必不独立**；奇妙的是，如果 $x_4$ 取值完全未知，则V型结构下 $x_1$ 和 $x_2$ 却是互相独立的。验证如下：
$$
\begin{eqnarray}
P(x_1, x_2)
&=& \sum_{x_4} P(x_1, x_2, x_4) \\
&=& \sum_{x_4} P(x_4 | x_1, x_2)P(x_1)P(x_2) \\
\tag{7.27}
&=& P(x_1)P(x_2).
\end{eqnarray}
$$
这样的独立性称为“**边际独立性(marginal independence)**”，记为 $x_1 \perp \!\!\! \perp x_2$.[^1]

为了分析有向图中变量间的条件独立性，可使用“有向分离(D-separation)”. 我们先把有向图转变为一个无向图：

- 找出有向图中的所有V型结构，在V型结构的两个父节点之间加上一条无向边；
- 将所有有向边改为无向边。

由此产生的无向图称为“道德图(moral graph)”，令父节点相连的过程称为“道德化(moralization)”[^2].

例子：

基于道德图能够直观而迅速地找到变量间的条件独立性。假定道德图中有变量 $x, y$ 和变量集合 $\mathbf{z} = \{ z_i\}$, 如果变量 $x$ 和 $y$ 能在图上被 $\mathbf{z}$ 分开，即从道德图中将变量集合 $\mathbf{z}$ 去除后， $x$ 和 $y$ 分属两个连通分支，则称变量 $x$ 和 $y$ 被 $\mathbf{z}$ 有向分离，$x \perp y | \mathbf{z}$ 成立。

**图7.2**所对应的道德图如**图7.4**所示，从图中能容易地找出所有的条件独立关系：
$$
x_3 \perp x_4 | x_1, \\
x_5 \perp x_4 | x_2, \\
x_3 \perp x_2 | x_1, \\
x_5 \perp x_3 | x_1, \\
x_5 \perp x_3 | x_2, \\
...
$$


![moral graph](./images/xgs_bayesian_network_moral_graph.png)



[^1]: 对变量或积分求和亦称“边际化(marginalizaiton)”. 实际上，一个变量取值的确定与否，能对另两个变量间的独立性发生影响，这个现象并非V型结构所特有。
[^2]: 也有翻译为“端正图”，“道德化”的蕴意：孩子的父母应该建立牢靠的关系，否则是不道德的。



### 学习

若网络结构已知，即属性间的依赖关系已知，则贝叶斯网的学习过程相对简单，只需要通过对训练样本“计数”，估计出每个节点的条件概率表即可。但在现实应用中我们往往并不知晓网络结构，于是，贝叶斯网的首要任务就是根据训练数据集来找出结构最“恰当”的贝叶斯网。

“评分搜索”时求解这一问题的常用办法。具体来说，我们先定义一个评分函数(score function)，以此来评估贝叶斯网与训练数据的契合程度，然后基于这个评分函数来寻找结构最优的贝叶斯网。显然，评分函数引入了关于我们希望获得什么样的贝叶斯网的归纳偏好。

---

> 归纳偏好
>
> 归纳偏好的作用在**图1.3**这个回归学习图示中可能更直观。这里的每个训练样本是图中的一个点 $(x, y)$，要学得一个与训练集一致的模型，相当于找到一条穿过所有样本点的曲线。显然，对有限个样本点组成的训练集，存在着很多条曲线与其一致。我们的学习算法必须有某种“偏好”，才能输出它认为“正确”的模型。
>
> 例如，若认为相似的样本应有相似的输出(比如，在各种属性上都很像的西瓜，成熟程度应该比较接近)，则对应的学习算法可能偏好**图1.3**中比较“平滑”的曲线A而不是比较“崎岖”的曲线B。
>
> ![curve fitted](./images/xgs_bayesian_network_occams_razor.png)
>
> 归纳偏好可看作学习算法自身在一个可能很庞大的假设空间中对假设进行选择的启发式或“价值观”。那么，有没有一般性的原则来引导算法确立“正确的”偏好呢？有，其中最基本的原则之一就是“奥卡姆剃刀(Occam's razor)”原则，即“如果有多个假设与观察一致，则选最简单的那个”。（假设我们认为，曲线A更平滑意味着更简单，曲线A的方程式要比曲线B的要简单得多，则在**图1.3**中我们自然会偏好“平滑的曲线A）。
>
> 事实上，归纳偏好对应了学习算法本身所做出的关于“什么样的模型更好”的假设。在具体问题中，这个假设是否成立，即算法的归纳偏好是否与问题本身匹配，大多数时候直接决定了算法能否取得好的性能。
>
> 基于前面讨论的“平滑”曲线的某种“描述简单性”，我们满怀信心地期待算法 $\cal{L}_a$ (曲线A) 比算法 $\cal{L}_b$ (曲线B) 更好。确实，如**图1.4a**所示，与 B 相比， A 与训练集外的样本更一致；换言之，A 的泛化性能比 B 好。但是，训练集外的样本会不会出现**图1.4b**的情况：与 A 相比，B 显然泛化性能更好。
>
> ![NFL](./images/xgs_bayesian_network_NFL.png)
>
> 这种情况完全可能出现。也就是说，对与一个学习算法 $\cal{L}_a$, 如果它在某些问题上比学习算法 $\cal{L}_b$ 好，则必然存在另外一些问题，在那里 $\cal{L}_b$ 要比 $\cal{L}_a$ 好。有趣的是，这个结论对任何算法均成立，哪怕是把一些“聪明的算法”与“随机胡猜”这样笨拙的算法进行对比。这就是“没有免费午餐”定理(No Free Lunch Theorem, NFL)[^3]。
>
> Q：既然所有学习算法的期望性能都跟随机胡猜差不多，那机器学习个啥？
>
> A：需要注意的是，NFL定理有一个重要前提：所有的“问题”出现的机会相同、或者所有问题同等重要。但实际情形远非如此。很多时候，我们只关注自己正在试图解决的问题，希望为它找到一个解决方案，至于这个解决方案在别的问题、甚至相似的问题上是否为好方案，我们不关心。例如，为了快速从a地点到达b地点，如果正在考虑的a地点是南京鼓楼、b地点是南京新街口，那么“骑自行车”是很好的解决方案；这个方案对a地点是南京鼓楼、b地点是北京新街口的情形显然很糟糕，但我们对此不关心。
>
> NFL定理最重要的寓意，是让我们清楚认识到，脱离具体问题，空谈什么学习算法更好，毫无意义，因为如果考虑所有潜在问题，则所有学习算法都一样好。要谈论算法的相对优劣，必须针对具体的学习问题，学习算法自身的归纳偏好与问题是否匹配，往往会起到决定性作用。

---

常用的评分函数通常基于信息论准则，此类准则将学习问题看作一个数据压缩任务，学习的目标是找到一个能以最短编码长度描述训练数据的模型，此时编码的长度包括了描述模型自身所需要的字节长度和使用该模型描述数据所需要的字节长度。对贝叶斯网学习而言，模型就是一个贝叶斯网，同时，每个贝叶斯网描述了一个在训练数据上的概率分布，自有一套编码机制能使那些经常出现的样本有更短的编码。于是，我们应该选择那个综合编码长度(包括描述贝叶斯网络和编码数据)最短的贝叶斯网，这就是“最小描述长度(Minimal Description Length, MDL)”准则。

给定训练集 $D = \{x_1, x_2, \ldots, x_m\}$[^4]，贝叶斯网 $B = \langle G, \Theta \rangle$ 在 $D$ 上的评分函数可写为
$$
\tag{7.28}
s(B | D) = f(\theta)|B| - LL(B | D),
$$
其中，$|B|$ 是贝叶斯网的参数个数；$f(\theta)$ 表示描述每个参数 $\theta$ 所需的字节数；而
$$
\tag{7.29} \label{eq:bn_ll}
LL(B | D) = \sum^m_{i=1} \text{log} P_B(x_i)
$$
是贝叶斯网 $B$ 的对数似然。显然，式(**7.28**)的第一项是计算编码贝叶斯网 $B$ 所需的字节数，第二项是计算 $B$ 所对应的概率分布 $P_B$ 需要多少字节来描述 $D$ . 于是，学习任务就转化为一个优化任务，即寻找一个贝叶斯网 $B$ 使得评分函数 $s(B | D)$ 最小。

- 若 $f(\theta) = 1$，即每个参数用1字节描述，则得到 **AIC** (Akaike Information Criterion)评分函数
  $$
  \tag{7.30}
  AIC(B | D) = |B| - LL(B | D).
  $$

- 若 $f(\theta) = {1 \over 2} \text{log}\ m$，即每个参数用 ${1 \over 2} \text{log}\ m$ 字节描述，则得到 **BIC** (Bayesian Information Criterion)评分函数
  $$
  \tag{7.31}
  BIC(B | D) = {\text{log}\ m\ \over 2} |B| - LL(B | D).
  $$

- 若 $f(\theta) = 0$，即不计算对网络进行编码的长度，则评分函数退化为负对数似然，相应的，学习任务退化为极大似然估计。

不难发现，若贝叶斯网 $B = \langle G, \Theta \rangle$ 的网络结构 $G$ 固定，则评分函数 $s(B | D)$ 的第一项为常数。此时，最小化 $s(B | D)$ 等价于对参数 $\Theta$ 的极大似然估计。由式($\ref{eq:bn_union_proba}$) 和式($\ref{eq:bn_ll}$)可知，参数 $\theta_{x_i | \pi_i}$ 能直接在训练数据 $D$ 上通过经验估计获得，即
$$
\tag{7.32}
\theta_{x_i | \pi_i} = \hat{P}_D(x_i | \pi_i),
$$
其中，$\hat{P}_D(\cdot)$ 是 $D$ 上的经验分布。因此，为了最小化评分函数 $s(B | D)$ ，只需对网络结构进行搜索，而候选结构的最优参数可直接在训练集上计算得到。

然而，从所有可能的网络结构空间搜索最优贝叶斯网结构是一个 NP 难问题，难以快速求解。有两种常用的策略能在有限时间内求得近似解：

- 贪心法：从某个网络结构出发，每次调整一条边（增加、删除、调整方向等），直到评分函数值不再降低为止；
- 结构约束：给网络结构施加约束条件来削减搜索空间，如将网络结构限定为树形结构。



### 推断

















[^3]: 详见《西瓜书》p.8。
[^4]: 这里把类别也看作一个属性，即 $x_i$ 是一个包括示例和类别的向量。



### EM 算法

在前面的讨论中，我们一直假设训练样本所有属性变量的值都已被观测到，即训练样本是“完整”的。但现实应用中往往会遇到“不完整”的训练样本，例如由于西瓜的根蒂已脱落，无法看出时“蜷缩”还是“硬挺”，则训练样本的“根蒂”属性变量值未知。在这种存在“未观测”变量的情形下，是否仍能对模型参数进行估计呢？

未观测变量的学名是“隐变量(latent variable)”。令 $X$ 表示已观测变量集， $Z$ 表示隐变量集，$\Theta$ 表示模型参数。要对 $\Theta$ 做极大似然估计，则应最大化对数似然
$$
\tag{7.34}
LL(\Theta | X,Z) = \text{ln} P(X,Z | \Theta).
$$
由于 $Z$ 是隐变量，上式无法直接求解。此时，我们可通过对 $Z$ 计算期望，来最大化已观测数据的对数“边际似然(marginal likelyhood)”
$$
\tag{7.35}
LL(\Theta | X) = \text{ln} P(X | \Theta) = \text{ln} \sum_{Z} P(X,Z | \Theta).
$$
EM(Expectation-Maximization) 算法是常用的迭代式估计参数隐变量的方法，其基本思想是：如果参数 $\Theta$ 已知，则可根据训练数据推断出最优隐变量 $Z$ 的值(E 步)；反之，如果 $Z$ 的值已知，则可方便地对参数 $\Theta$ 做极大似然估计(M 步)。

于是，以初始值 $\Theta^{0}$ 为起点，对式(**7.35**)，可迭代执行以下步骤直至收敛：

- 基于 $\Theta^{t}$ 推断隐变量 $Z$ 的期望，记为 $Z^{t}$ ；
- 基于已观测变量 $X$ 和 $Z^{t}$ 对参数 $\Theta$ 做极大似然估计，记为 $\Theta^{t+1}$ ;

这就是EM算法的原型。

如果我们不是取 $Z$ 的期望，而是基于 $\Theta^{t}$ 计算隐变量 $Z$ 的概率分布 $P(Z | X,\Theta^{t})$ ，则EM算法的两个步骤是：

- E 步(Expectation)：以当前参数 $\Theta^{t}$ 推断隐变量分布 $P(Z | X,\Theta^{t})$ ，并计算对数似然 $LL(\Theta | X,Z)$ 关于 $Z$ 的期望
  $$
  \tag{7.36}
  Q(\Theta | \Theta^{t}) = \mathbb{E}_{Z|X,\Theta^{t}} LL(\Theta | X,Z).
  $$

- M 步(Maximization)：寻找参数最大化期望似然，即
  $$
  \tag{7.37}
  Q^{t+1} = \underset{\Theta}{\operatorname{argmax}}\ Q(\Theta | \Theta^{t}).
  $$

可简述为：

EM算法[^5]使用两个步骤交替计算：第一步是期望(E)步，利用当前估计的参数值来计算对数似然的期望值；第二步是最大化(M)步，寻找能使E步产生的似然期望最大化的参数值。然后，新得到的参数值重新被用于E步，......直至收敛到局部最优解。





[^5]: EM算法可看作用坐标下降(coordinate descent)法来最大化对数似然下界的过程。事实上，隐变量估计也可以通过梯度下降算法求解，但由于求和的项数将随着隐变量的数目以指数级上升，会给梯度计算带来麻烦；而EM算法则可看作一种非梯度优化方法。