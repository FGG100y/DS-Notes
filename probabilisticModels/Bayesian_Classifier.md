## Bayesian Classifier

### 贝叶斯决策论

贝叶斯决策论(Bayesian decision theory)是概率框架下实施决策的基本方法。对分类任务来说，在所有相关概率都已知的情况下，贝叶斯决策论考虑如何基于这些概率和误判损失来选择最优的类别标记。

例子：

假设有 $N$ 种可能的类别标记，即 $\mathcal{Y} = \{c_1, c_2, \ldots, c_N\}$ ，$\lambda_{ij}$ 是将一个真实标记为 $c_j$ 的样本误分类为 $c_i$ 所产生的损失。

基于后验概率 $P(c_i | x)$ 可获得将样本 $x$ 分类为 $c_i$ 所产生的期望损失(expected loss)，即在样本 $x$ 上的“条件风险(condictional risk)”[^1]
$$
\tag{7.1}
R(c_i|x) = \sum^{N}_{j=1} \lambda_{ij} P(c_j|x).
$$
我们的任务是寻找一个判定准则 $h: \cal{X} \mapsto \cal{Y}$ 以最小化总体风险
$$
\tag{7.2}
R(h) = \mathbb{E}_x[R(h(x)|x)].
$$
显然，对每个样本 $x$ ，如果 $h$ 能最小化条件风险 $R(h(x)|x)$ ，则总体风险 $R(h)$ 也将被最小化。这就产生了贝叶斯判断准则(Bayesian decision rule)：为最小化总体分析，只需在每个样本上选择那个能使条件风险 $R(c|x)$ 最小的类别标记，即
$$
\tag{7.3}
h^{*}(x) = \underset{c \in \cal{Y}}{\operatorname{argmax}}\ R(c|x),
$$
此时，$h^{*}$ 称为贝叶斯最优分类器(Bayesian optimal classifier)，与之相应的总体风险 $R(h^{*})$ 称为贝叶斯风险(Bayes risk)。$1 - R(h^{*})$ 反映了分类器所能达到的最好性能，即通过机器学习所能产生的模型精度的理论上限。

具体而言，如果目标是最小化分类错误率[^2]，则误判损失 $\lambda_{ij}$ 可写为
$$
\tag{7.4}
\lambda_{ij} = 
\left\{ 
    \begin{array}{ll}
    0, & \textrm{if $i = j$}; \\
    1, & \textrm{otherwise},
    \end{array}
\right.
$$
此时，条件风险
$$
\tag{7.5}
R(c|x) = 1 - P(c|x),
$$

> 在 $0/1$ 损失函数情况下，条件风险为 $0$，当 $\lambda_{ij} = 0$ 时(即分类正确时误判损失为0)；后验概率 $P(c_i | x)$ 就是指将样本分类正确的概率；那么只有在 $\lambda_{ij} = 1$ 时条件风险的值不为 $0$，其值就是 $1 * (1 - P(c|x))$ 。

于是，最小化分类错误率的贝叶斯最优分类器为
$$
\tag{7.6} \label{eq:Bayes_principle}
h^{*}(x) = \underset{c \in \cal{Y}}{\operatorname{argmax}}\ P(c|x),
$$
即对每个样本 $x$ ，选择能使后验概率 $P(c|x)$ 最大的类别标记。

因此，要使用贝叶斯判断准则来最小化决策风险，首先要获得后验概率 $P(c|x)$ [^3]。然而，在现实任务中这通常难以直接获得。从这个角度来看，机器学习所要实现的是基于有限的训练样本尽可能准确地估计出后验概率$P(c|x)$ 。两种策略：

- 通过直接建模 $P(c|x)$ 来预测 $c$ ，这样得到的是“判别式模型(discriminative models)”，如决策树、BP神经网络、支持向量机等;
- 通过先对联合概率分布 $P(x, c)$ 建模，然后再由此获得 $P(c|x)$ ，这是“生成式模型(generative models)”，如贝叶斯网、隐马尔可夫模型(HMM)、混合高斯(GMM)等。

对生成式模型来说，根据概率乘法法则[^4]有
$$
\tag{7.7}
P(c|x) = {P(x,c) \over P(x)}.
$$
基于贝叶斯定理[^5]，$P(c|x)$ 可写为
$$
\tag{7.8} \label{eq:Bayes_equation}
P(c|x) = {P(c)P(x|c) \over P(x)},
$$
其中，$P(c)$ 是类“先验(prior)”概率；$P(x|c)$ 是样本 $x$ 相对于类标记 $c$ 的类条件概率(class-condictional probability)，或称为“似然(likelyhood)”；$P(x)$ 是用于归一化的“证据(evidence)”因子。对给定样本 $x$ ，证据因子 $P(x)$ 与类标记无关(对所有样本都一样)，因此估计 $P(c|x)$ 的问题就转化成如何基于训练数据 $D$ 来估计先验 $P(x)$ 和似然 $P(x|c)$ 。

类先验概率 $P(c)$ 表达了样本空间中各类样本所占的比例，根据大数定律[^6]，当训练集包含充足的独立同分布(iid)样本时，$P(c)$ 可通过各类样本出现的频率来进行估计。

对类条件概率 $P(x|c)$ 来说，由于它涉及关于 $x$ 所有属性的联合概率，直接根据样本出现的频率来估计将会遇到严重的困难。例如，假设样本的 $d$ 个属性都是二值的，则样本空间将有 $2^d$ 种可能的取值，在现实应用中，这个值往往远大于训练样本数目 $m$ ，也就是说，很多样本的取值在训练集中根本没有被记录到，直接使用频率来估计 $P(x|c)$ 显然不可行，因为“未被观测到”并不等于“出现概率为零”。

### 极大似然估计

估计类条件概率的一种常用策略是先假定其具有某种确定的概率分布形式，再基于训练样本对概率分布的参数进行估计。具体来说，记关于类别 $c$ 的类条件概率为 $P(x|c)$ ，假设 $P(x|c)$ 具有确定的形式并且并参数向量 $\theta_c$ 唯一确定，则我们的任务就是利用训练集 $D$ 估计参数 $\theta_c$ 。为明确起见，将 $P(x|c)$ 记为 $P(x|\theta_c)$ 。

事实上，概率模型的训练过程就是参数估计(parameter estimation)过程。

对于参数估计，统计学界的两个学派分别提供了不同的解决方案[^7]：

- 频率主义学派(Frequentist)认为参数虽然未知，但却是客观存在的**固定值**，因此，可通过优化似然函数等准则来确定参数值；
- 贝叶斯学派(Bayesian)则认为参数是未观察到的**随机变量**，其本身也可有分布，因此，可假定参数服从一个先验分布，然后基于观测到的数据来计算参数的后验分布。

源自频率主义学派的极大似然估计(Maximum Likelyhood Estimation, MLE)，是根据数据采样来估计概率分布的经典方法。MLE的一般过程为：

令 $D_c$ 表示训练集 $D$ 中第 $c$ 类样本组成的集合，假设这些样本是独立同分布的，则参数 $\theta_c$ 对于数据集 $D_c$ 的似然是
$$
\tag{7.9}
P(D_c|\theta_c) = \prod_{x \in D_c} P(x | \theta_c).
$$
对 $\theta_c$ 进行极大似然估计，就是寻找能最大化似然 $P(D_c|\theta_c)$ 的参数值 $\hat{\theta}_c$ 。直观上看，极大似然估计是试图在 $\theta_c$ 所有可能的取值中，找到一个能使数据出现的“可能性”最大的值。

式(**7.9**)中的连乘容易造成下溢[^8]，通常使用对数似然(log-likelyhood)
$$
\begin{eqnarray}
LL(\theta_c)
&=& \text{log}\ P(D_c|\theta_c) \\
\\
\tag{7.10}
&=& \sum_{x \in D_c} \text{log}\ P(x|\theta_c),
\end{eqnarray}
$$
此时，参数 $\theta_c$ 的极大似然估计 $\hat{\theta}_c$ 为
$$
\tag{7.11}
\hat{\theta}_c = \underset{\theta_c}{\operatorname{argmax}}\ LL(\theta_c).
$$
这时候，如果假设类条件概率服从某种分布，比如说，在连续属性情况下，假设概率密度函数 $p(x|c) \sim \cal{N}(\mu_c, \sigma^{2}_{c})$ ，则参数 $\mu_c, \sigma^{2}_{c}$ 的极大似然估计为
$$
\begin{eqnarray}
    \tag{7.12}
    \hat{\mu}_c
    &=& {1 \over |D_c|} \sum_{x \in D_c} x, \\
    \\
    \tag{7.13}
    \hat{\sigma}^{2}_{c}
    &=& {1 \over |D_c|} \sum_{x \in D_c}
    (x - \hat{\mu}_c)(x - \hat{\mu}_c)^{T}.
\end{eqnarray}
$$
也就是说，通过极大似然估计得到的正态分布均值就是样本均值，方差就是 $(x - \hat{\mu}_c)(x - \hat{\mu}_c)^{T}$ 的均值，这显然是一个符合我们直觉的结果[^9]。在离散属性情形下，也可通过类似的方式估计类条件概率。

### 朴素贝叶斯分类器

直接基于贝叶斯公式($\ref{eq:Bayes_equation}$)来估计后验概率 $P(c|x)$ 的主要困难在于：类条件概率 $P(x|c)$ 是所有属性上的联合概率，难以从有限的训练样本直接估计而得。

为避开这个障碍，朴素贝叶斯分类器(naive Bayes classifier)采用了“属性条件独立假设(attribute conditional independence assumption)”：对已知类别，假设所有属性互相独立。换言之，假设每个属性独立地对分类结果发生影响。

基于属性条件独立性假设，根据概率乘法法则[^4]，式($\ref{eq:Bayes_equation}$)可以重写为
$$
\tag{7.14}
P(c|x)
= {P(c)P(x|c) \over P(x)}
= {P(c) \over P(x)} \prod^{d}_{i=1} P(x_i|c),
$$
其中，$d$ 为属性数目，$x_i$ 为 $x$ 在第 $i$ 个属性上的取值[^10]。

由于对所有类别来说 $P(x)$ 相同，因此基于式($\ref{eq:Bayes_principle}$)的贝叶斯判定准则有
$$
\tag{7.15}
h_{nb}(x) = 
\underset{c \in \cal{Y}}{\operatorname{argmax}}\ 
P(c) \prod^{d}_{i=1} P(x_i|c).
$$
这就是朴素贝叶斯分类器的表达式。

显然，朴素贝叶斯分类器的训练过程就是基于训练集 $D$ 来估计类先验概率 $P(c)$ ，并估计每个属性的条件概率 $P(x_i|c)$ 。

令 $D_c$ 表示训练集 $D$ 中第 $c$ 类样本组成的集合，假设这些样本是独立同分布的，在拥有充足的训练样本时，可容易地估计出类先验概率
$$
\tag{7.16}
P(c) = {|D_c| \over |D|}.
$$
对离散属性而言，令 $D_{c,x_i}$ 表示 $D_c$ 中在第 $i$ 个属性上取值为 $x_i$ 的样本组成的集合，则条件概率 $P(x_i|c)$ 可估计为
$$
\tag{7.17}
P(x_i|c) = {D_{c,x_i} \over |D_c|}.
$$
对连续属性可考虑概率密度函数，假定 $p(x_i|c) \sim \cal{N}(\mu_{c,i}, \sigma^{2}_{c,i})$ ，其中 $\mu_{c,i},\ \sigma^{2}_{c,i}$ 分别是第 $c$ 类样本在第 $i$ 个属性上取值的均值和方差，则有
$$
\tag{7.18}
p(x_i|c) = 
{1 \over \sqrt{2\pi}\ \sigma^{2}_{c,i}} 
\text{exp} 
    \bigg(
    - \frac{(x_i - \mu_{c,i})^2}{2 \sigma^{2}_{c,i}}
    \bigg).
$$


需注意：如果某个属性值在训练集中没有与某个类同时出现过，则直接基于式(**7.17**)进行概率估计，在根据式(**7.15**)进行判别将出现问题。比如，（西瓜数据集）对一个“敲声：清脆”的测试例，有
$$
P(\text{清脆|是}) = P(\text{敲声=清脆|好瓜=是}) = {0 \over 8} = 0,
$$
于式(**7.15**)的连乘式计算出的概率值为零，因此无论该样本的其他属性是什么，哪怕在其他属性上明显是“好瓜”，分类的结果都将是“好瓜：否”，这不合理。

为了避免其他属性携带的信息被训练集中未出现的属性值“抹去”，在估计概率值时通常需要进行“平滑(smoothing)”，常用“拉普拉斯修正(Laplacian correction)”。具体就是，令 $N$ 表示训练集 $D$ 中可能的类别数目，$N_i$ 表示第 $i$ 个属性可能的取值数目，则式(**7.16**)和式(**7.17**)分别修正为
$$
\tag{7.19}
\hat{P}(c) = \frac{|D_c| + 1}{|D| + N},
$$

$$
\tag{7.20}
\hat{P}(x_i|c) = \frac{|D_{c,i}| + 1}{|D_c| + N_i}.
$$

显然，拉普拉斯修正避免了因训练集样本不充分而导致概率估值为零的问题，并且在训练集变大时，修正过程引入的先验(prior)的影响也会逐渐变得可忽略，使得估值趋向于实际概率值。

#### 现实应用实现方式

- 如果任务对预测速度要求高，则给定训练集，可将朴素贝叶斯分类器涉及的所有概率估计值事先计算好存储起来，这样在进行预测时只需“查表”即可进行判别；
- 如果任务数据更新频繁，则可采用“懒惰学习(lazy learning)”方式，先不进行任何训练，待收到预测请求时再根据当前数据集进行概率估值；
- 如果数据不断增加，则可在现有估值基础上，仅对新增样本的属性值所涉及的概率估值进行计数修正即可实现增量学习(increamental learning)。





[^1]: 决策论中将“期望损失”称为“风险”。
[^2]: 错误率对应于 $0/1$ 损失函数。
[^3]: 事实上，很多机器学习技术无须准确估计出后验概率就能准确进行分类。
[^4]: 概率乘法法则(product rule): $P(x,y) = P(y|x)P(x)$; 概率加法法则(sum rule): $P(x) = \sum_{y}P(x,y)$ ，详见《Pattern Recognition and Machine Learning》Chap1, p.14。
[^5]: 根据概率乘法法则，以及对称性 $P(x,y) = P(y,x)$ ，我们可以得到概率条件之间的关系：$P(y|x)P(x) = P(x|y)P(y) \Rightarrow P(y|x) = {P(x|y)P(y) \over P(x)}$ ，这就是所谓的“贝叶斯定理”。根据概率加法法则，贝叶斯定理的分母可写为：$P(x)=\sum_{y}P(x|y)P(y)$ ，这就是所谓的“归一化因子”。
[^6]: 详见 David Freedman等人的著作《Statistics》Chap16 : "The Law of Average"，Chap18: "The Normal Approximation for Probability Histograms".
[^7]: 参考另一篇笔记 “Linear regression” PartII: MAP & MLE.
[^8]: 当那些接近于零的数值被约为零时(rounded to zero)，后续的计算中可能就会因此出现，比如除数为零的情况，这就造成下溢(underflow)的发生。
[^9]: 在现实应用任务中，想要做出能比较好地接近潜在真实分布的假设，往往需要在一定程度上利用关于应用任务本身的经验知识，否则仅凭“猜测”来假设概率分布形式，很可能产生误导性的结果。
[^10]: $x_i$ 实际上是一个“属性：值”对，例如“色泽：青绿”。为便于讨论，在上下文明确时，有时用 $x_i$ 表示第 $i$ 属性对应的变量“色泽”，有时指其取值，如“青绿”。

